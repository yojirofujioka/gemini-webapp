import streamlit as st
import vertexai
from vertexai.generative_models import GenerativeModel, Part
import json
import re
from google.oauth2 import service_account
from datetime import date
import math
from PIL import Image
import io
import html
import base64

# ----------------------------------------------------------------------
# 1. ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³è¨­å®š
# ----------------------------------------------------------------------
st.set_page_config(
    page_title="ç¾å ´åˆ†æãƒ¬ãƒãƒ¼ãƒˆ",
    page_icon="ğŸ“±",
    layout="wide",
    initial_sidebar_state="collapsed"
)
BATCH_SIZE = 5  # ãƒ¢ãƒã‚¤ãƒ«ç’°å¢ƒã‚’è€ƒæ…®ã—ã€ä¸€åº¦ã«å‡¦ç†ã™ã‚‹æšæ•°ã‚’èª¿æ•´

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ï¼ˆã‚¢ãƒ—ãƒªã®çŠ¶æ…‹ã‚’ä¿å­˜ã™ã‚‹å ´æ‰€ï¼‰ã®åˆæœŸåŒ–
if 'processing' not in st.session_state:
    st.session_state.processing = False
if 'report_payload' not in st.session_state:
    st.session_state.report_payload = None
if 'files_dict' not in st.session_state:
    st.session_state.files_dict = None
if 'edit_mode' not in st.session_state:
    st.session_state.edit_mode = False
if 'edited_report' not in st.session_state:
    st.session_state.edited_report = None

# ----------------------------------------------------------------------
# 2. ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰èªè¨¼
# ----------------------------------------------------------------------
def check_password():
    """Secretsã«ä¿å­˜ã•ã‚ŒãŸãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã§èªè¨¼ã‚’è¡Œã†"""
    try:
        PASSWORD = st.secrets["PASSWORD"]
    except (KeyError, FileNotFoundError):
        st.error("ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        st.info("ã“ã®ã‚¢ãƒ—ãƒªã‚’å®Ÿè¡Œã™ã‚‹ã«ã¯ã€secrets.tomlãƒ•ã‚¡ã‚¤ãƒ«ã«'PASSWORD = \"ã‚ãªãŸã®ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰\"'ã‚’è¨­å®šã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚")
        st.stop()

    if "password_correct" not in st.session_state:
        st.session_state.password_correct = False

    if not st.session_state.password_correct:
        password = st.text_input("ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", type="password")
        if st.button("ãƒ­ã‚°ã‚¤ãƒ³"):
            if password == PASSWORD:
                st.session_state.password_correct = True
                st.rerun()
            else:
                st.error("ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãŒé–“é•ã£ã¦ã„ã¾ã™ã€‚")
        st.stop()
    return True


# ----------------------------------------------------------------------
# 3. ãƒ‡ã‚¶ã‚¤ãƒ³ã¨GCPåˆæœŸåŒ–
# ----------------------------------------------------------------------
def inject_custom_css():
    """ãƒ¢ãƒã‚¤ãƒ«è¡¨ç¤ºã«æœ€é©åŒ–ã—ãŸã‚«ã‚¹ã‚¿ãƒ CSS"""
    st.markdown("""
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <style>
        /* å…¨ä½“ã®èƒŒæ™¯ã¨æ–‡å­—è‰² */
        .stApp {
            background-color: #f0f2f6;
        }
        /* ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚¨ãƒªã‚¢ã®ä½™ç™½èª¿æ•´ */
        .block-container {
            padding: 1rem 1rem 3rem 1rem !important;
        }
        /* ã‚«ãƒ¼ãƒ‰ã‚¹ã‚¿ã‚¤ãƒ«ã®åŸºæœ¬ */
        .card {
            background: #ffffff;
            border-radius: 12px;
            padding: 16px;
            margin-bottom: 16px;
            box-shadow: 0 4px 6px rgba(0,0,0,0.05);
            border: 1px solid #e5e7eb;
        }
        /* å†™çœŸã®ã‚¹ã‚¿ã‚¤ãƒ« */
        .stImage img {
            border-radius: 8px;
            box-shadow: 0 4px 6px rgba(0,0,0,0.1);
        }
        /* æŒ‡æ‘˜äº‹é …ã‚«ãƒ¼ãƒ‰ã®ã‚¹ã‚¿ã‚¤ãƒ« */
        .finding-card {
            padding: 12px;
            border-radius: 8px;
            margin-top: 12px;
            border-left: 5px solid;
        }
        .finding-high { border-color: #ef4444; background-color: #fef2f2; }
        .finding-medium { border-color: #f97316; background-color: #fff7ed; }
        .finding-low { border-color: #3b82f6; background-color: #eff6ff; }
        
        .finding-location {
            font-weight: bold;
            font-size: 1.1em;
            color: #1f2937;
            margin-bottom: 8px;
        }
        .finding-details p {
            margin-bottom: 4px;
            line-height: 1.5;
            color: #374151;
        }
        .finding-details strong {
            color: #111827;
        }
        /* æ‰€è¦‹ãƒ»å•é¡Œãªã—ãƒœãƒƒã‚¯ã‚¹ */
        .observation-box {
            background-color: #f0fdf4;
            border-left: 5px solid #22c55e;
            padding: 12px;
            border-radius: 8px;
            margin-top: 12px;
        }
        /* ãƒœã‚¿ãƒ³ã®ã‚¹ã‚¿ã‚¤ãƒ« */
        .stButton button {
            width: 100%;
            border-radius: 8px;
            font-weight: bold;
        }
    </style>
    """, unsafe_allow_html=True)

@st.cache_resource
def initialize_vertexai():
    """GCPã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆæƒ…å ±ã‚’ä½¿ã£ã¦Vertex AIã‚’åˆæœŸåŒ–"""
    try:
        gcp_secrets = st.secrets["gcp"]
        service_account_info = json.loads(gcp_secrets["gcp_service_account"])
        credentials = service_account.Credentials.from_service_account_info(service_account_info)
        vertexai.init(project=gcp_secrets["project_id"], location="asia-northeast1", credentials=credentials)
        return GenerativeModel("gemini-1.5-pro")
    except Exception as e:
        st.error(f"GCPã®èªè¨¼ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        st.info("secrets.tomlãƒ•ã‚¡ã‚¤ãƒ«ã«GCPã®èªè¨¼æƒ…å ±ãŒæ­£ã—ãè¨­å®šã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        return None

# ----------------------------------------------------------------------
# 4. AIã¨ãƒ‡ãƒ¼ã‚¿å‡¦ç†
# ----------------------------------------------------------------------
def create_report_prompt(filenames):
    """ç¾å ´ã§ã®ç¢ºèªã«æœ€é©åŒ–ã•ã‚ŒãŸã€ç°¡æ½”ã‹ã¤é‡è¦ãªæƒ…å ±ã‚’é‡è¦–ã™ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ"""
    file_list_str = "\\n".join([f"- {name}" for name in filenames])
    return f"""
    ã‚ãªãŸã¯æ—¥æœ¬ã®ãƒªãƒ•ã‚©ãƒ¼ãƒ å·¥äº‹å°‚é–€ã®ãƒ™ãƒ†ãƒ©ãƒ³ç¾å ´ç›£ç£ã§ã™ã€‚æä¾›ã•ã‚ŒãŸç¾å ´å†™çœŸã‚’åˆ†æã—ã€æ–°äººç›£ç£ãŒã‚¹ãƒãƒ›ã§ç¢ºèªã—ãªãŒã‚‰ä½¿ãˆã‚‹ã€å…·ä½“çš„ã§å®Ÿç”¨çš„ãªä¿®ç¹•æŒ‡ç¤ºãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

    ã€é‡è¦–ã™ã‚‹ç‚¹ã€‘
    - **è¦‹è½ã¨ã—é˜²æ­¢**: æ–°äººãŒè¦‹é€ƒã—ãŒã¡ãªç´°ã‹ã„ç‚¹ã‚‚æŒ‡æ‘˜ã™ã‚‹ã€‚
    - **å…·ä½“çš„ãªæŒ‡ç¤º**: ä½•ã‚’ã™ã¹ãã‹æ˜ç¢ºã«è¨˜è¿°ã™ã‚‹ã€‚
    - **ãƒªã‚¹ã‚¯å›é¿**: å¯¸æ³•é–“é•ã„ã‚„ä»•æ§˜é•ã„ãŒèµ·ãã‚„ã™ã„ç‚¹ã«ã¤ã„ã¦æ³¨æ„å–šèµ·ã™ã‚‹ã€‚

    ã€å„æŒ‡æ‘˜äº‹é …ã«å«ã‚ã‚‹æƒ…å ±ã€‘
    - "location": (string) ã©ã“ã§å•é¡ŒãŒèµ·ãã¦ã„ã‚‹ã‹ã€‚ï¼ˆä¾‹ï¼šã€Œãƒªãƒ“ãƒ³ã‚°åŒ—å´å£ã€åºŠã‹ã‚‰30cmã®é«˜ã•ã€ï¼‰
    - "current_state": (string) ä½•ãŒã©ã†ãªã£ã¦ã„ã‚‹ã‹ã€‚ï¼ˆä¾‹ï¼šã€Œå¹…5cmã®æ“¦ã‚Šå‚·ã¨ã€æ·±ã•2mmã®å‡¹ã¿ã€ï¼‰
    - "suggested_work": (string) å…·ä½“çš„ã«ä½•ã‚’ã™ã¹ãã‹ã€‚ï¼ˆä¾‹ï¼šã€Œãƒ‘ãƒ†ã§è£œä¿®å¾Œã€éƒ¨åˆ†çš„ãªã‚¯ãƒ­ã‚¹å¼µæ›¿ãˆã€‚å“ç•ªã¯AA-1234ã€ï¼‰
    - "priority": (string) ã€Œé«˜ã€ã€Œä¸­ã€ã€Œä½ã€ã®3æ®µéšè©•ä¾¡ã€‚
    - "notes": (string) æ–°äººã¸ã®ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã€‚ï¼ˆä¾‹ï¼šã€Œæ¡å¯¸æ™‚ã¯çª“æ ã®å†…å¯¸ã‚‚æ¸¬ã‚‹ã“ã¨ã€‚çµéœ²ã«ã‚ˆã‚‹ä¸‹åœ°ã®è…é£Ÿã‚‚ç¢ºèªã€‚ã€ï¼‰

    **æœ€é‡è¦**: å‡ºåŠ›ã¯ç´”ç²‹ãªJSONæ–‡å­—åˆ—ã®ã¿ã¨ã™ã‚‹ã“ã¨ã€‚èª¬æ˜æ–‡ã‚„ ```json ... ``` ã®ã‚ˆã†ãªãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ã¯çµ¶å¯¾ã«å«ã‚ãªã„ã§ãã ã•ã„ã€‚

    **JSONã®æ§‹é€ **:
    `[ {{ "file_name": "...", "findings": [{{...}}], "observation": "..." }}, ... ]`
    ã¨ã„ã†å½¢å¼ã®ãƒªã‚¹ãƒˆã«ã—ã¦ãã ã•ã„ã€‚
    - "findings" ãŒãªã„å ´åˆã¯ã€"observation" ã«ã€Œè¨­å‚™ã¯æ­£å¸¸ã€‚å®šæœŸæ¸…æƒã‚’æ¨å¥¨ã€ã®ã‚ˆã†ã«å†™çœŸã‹ã‚‰åˆ†ã‹ã‚‹çŠ¶æ…‹ã‚’è¨˜è¿°ã—ã¦ãã ã•ã„ã€‚
    - "findings" ãŒã‚ã‚‹å ´åˆã€"observation" ã¯ç©ºæ–‡å­—åˆ— `""` ã«ã—ã¦ãã ã•ã„ã€‚

    åˆ†æå¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«: {file_list_str}
    ãã‚Œã§ã¯ã€åˆ†æã‚’é–‹å§‹ã—ã¦ãã ã•ã„ã€‚ãƒ—ãƒ­ã®ç›®ã§ã€ç¾å ´ã§æœ¬å½“ã«å½¹ç«‹ã¤ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
    """

def generate_ai_report(model, file_batch, prompt):
    """ç”»åƒã¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’AIã«é€ã‚Šã€ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
    image_parts = [Part.from_data(f.getvalue(), mime_type=f.type) for f in file_batch]
    response = model.generate_content([prompt] + image_parts, request_options={"timeout": 120})
    return response.text

def parse_json_response(text):
    """AIã®å¿œç­”ã‹ã‚‰JSONéƒ¨åˆ†ã‚’å®‰å…¨ã«æŠ½å‡ºã—ã¦è§£æ"""
    # ```json ... ``` ã‚„ ``` ... ``` ã§å›²ã¾ã‚Œã¦ã„ã‚‹å ´åˆã‚’è€ƒæ…®
    match = re.search(r'```(json)?\s*(.*?)\s*```', text, re.DOTALL)
    json_str = match.group(2) if match else text
    try:
        return json.loads(json_str)
    except json.JSONDecodeError as e:
        st.error(f"AIã‹ã‚‰ã®å¿œç­”ã‚’JSONã¨ã—ã¦è§£æã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
        st.info("AIã‹ã‚‰ã®ç”Ÿã®å¿œç­”:")
        st.code(text, language="text")
        return None

# ----------------------------------------------------------------------
# 5. ãƒ¬ãƒãƒ¼ãƒˆè¡¨ç¤º
# ----------------------------------------------------------------------
def display_report(report_payload, files_dict):
    """ç”Ÿæˆã•ã‚ŒãŸãƒ¬ãƒãƒ¼ãƒˆã‚’ãƒ¢ãƒã‚¤ãƒ«ãƒ•ãƒ¬ãƒ³ãƒ‰ãƒªãƒ¼ã«è¡¨ç¤º"""
    report_data = report_payload.get('report_data', [])
    report_title = report_payload.get('title', '')
    survey_date = report_payload.get('date', '')

    st.markdown(f"### {report_title}")
    st.caption(f"èª¿æŸ»æ—¥: {survey_date}")
    
    # --- ã‚µãƒãƒªãƒ¼è¡¨ç¤º ---
    total_findings = sum(len(item.get("findings", [])) for item in report_data)
    high_priority_count = sum(1 for item in report_data for f in item.get("findings", []) if f.get("priority") == "é«˜")
    
    st.markdown('<div class="card">', unsafe_allow_html=True)
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("å†™çœŸæšæ•°", f"{len(report_data)}æš")
    with col2:
        st.metric("æŒ‡æ‘˜ä»¶æ•°", f"{total_findings}ä»¶")
    with col3:
        st.metric("ç·Šæ€¥åº¦ã€Œé«˜ã€", f"{high_priority_count}ä»¶", delta=f"-{high_priority_count}" if high_priority_count > 0 else "0")
    st.markdown('</div>', unsafe_allow_html=True)

    # --- è©³ç´°åˆ†æçµæœ ---
    st.subheader("è©³ç´°åˆ†æçµæœ")
    for i, item in enumerate(report_data):
        st.markdown(f'<div class="card">', unsafe_allow_html=True)
        # å†™çœŸã‚’è¡¨ç¤º
        if files_dict and item.get('file_name') in files_dict:
            st.image(files_dict[item['file_name']], caption=f"{i + 1}. {item['file_name']}", use_column_width=True)
        
        # æŒ‡æ‘˜äº‹é …ã‚’è¡¨ç¤º
        findings = item.get("findings", [])
        if findings:
            for finding in findings:
                priority = finding.get('priority', 'ä¸­').lower()
                location = finding.get('location', 'å ´æ‰€æœªè¨˜è¼‰')
                current_state = finding.get('current_state', '')
                suggested_work = finding.get('suggested_work', '')
                notes = finding.get('notes', '')

                st.markdown(f'<div class="finding-card finding-{priority}">', unsafe_allow_html=True)
                st.markdown(f'<div class="finding-location">{location} [ç·Šæ€¥åº¦: {priority.upper()}]</div>', unsafe_allow_html=True)
                details_html = f"""
                <div class="finding-details">
                    <p><strong>ç¾çŠ¶:</strong> {html.escape(current_state)}</p>
                    <p><strong>ææ¡ˆ:</strong> {html.escape(suggested_work)}</p>
                """
                if notes:
                    details_html += f'<p><strong>å‚™è€ƒ:</strong> {html.escape(notes)}</p>'
                details_html += "</div>"
                st.markdown(details_html, unsafe_allow_html=True)
                st.markdown('</div>', unsafe_allow_html=True)
        
        # æ‰€è¦‹ã¾ãŸã¯å•é¡Œãªã—ã®å ´åˆ
        elif item.get("observation"):
            st.markdown(f'<div class="observation-box"><strong>æ‰€è¦‹:</strong> {html.escape(item["observation"])}</div>', unsafe_allow_html=True)
        else:
            st.markdown('<div class="observation-box">âœ” ä¿®ç¹•ã®å¿…è¦ç®‡æ‰€ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚</div>', unsafe_allow_html=True)

        st.markdown('</div>', unsafe_allow_html=True)

# ----------------------------------------------------------------------
# 6. ãƒ¡ã‚¤ãƒ³å‡¦ç†
# ----------------------------------------------------------------------
def main():
    inject_custom_css()
    
    st.title("ğŸ“± ç¾å ´å†™çœŸ åˆ†æãƒ¬ãƒãƒ¼ãƒˆ")

    if not check_password():
        return
    
    model = initialize_vertexai()
    if not model:
        st.stop()

    # --- ãƒ¬ãƒãƒ¼ãƒˆè¡¨ç¤ºç”»é¢ ---
    if st.session_state.report_payload:
        display_report(st.session_state.report_payload, st.session_state.files_dict)
        if st.button("âœ¨ æ–°ã—ã„ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã™ã‚‹"):
            st.session_state.clear()
            st.rerun()
        return

    # --- ãƒ¬ãƒãƒ¼ãƒˆä½œæˆï¼ˆå…¥åŠ›ï¼‰ç”»é¢ ---
    st.header("ãƒ¬ãƒãƒ¼ãƒˆä½œæˆ")
    with st.form("report_form"):
        report_title = st.text_input("ç‰©ä»¶åãƒ»æ¡ˆä»¶å", "ï¼ˆä¾‹ï¼‰ã€‡ã€‡ãƒ“ãƒ« 301å·å®¤ åŸçŠ¶å›å¾©å·¥äº‹")
        survey_date = st.date_input("èª¿æŸ»æ—¥", date.today())
        
        uploaded_files = st.file_uploader(
            "åˆ†æã—ãŸã„å†™çœŸã‚’é¸æŠï¼ˆè¤‡æ•°å¯ï¼‰",
            type=["png", "jpg", "jpeg"],
            accept_multiple_files=True
        )
        
        submitted = st.form_submit_button(
            "åˆ†æã‚’é–‹å§‹ã™ã‚‹",
            type="primary",
            disabled=st.session_state.processing
        )

    if submitted and not uploaded_files:
        st.warning("å†™çœŸã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")

    if submitted and uploaded_files:
        st.session_state.processing = True
        st.rerun() # UIã‚’æ›´æ–°ã—ã¦å‡¦ç†ä¸­è¡¨ç¤ºã«åˆ‡ã‚Šæ›¿ãˆã‚‹

    if st.session_state.processing:
        st.info("AIã«ã‚ˆã‚‹åˆ†æã‚’é–‹å§‹ã—ã¾ã—ãŸã€‚å†™çœŸã®æšæ•°ã«å¿œã˜ã¦æ•°åˆ†ã‹ã‹ã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚")
        progress_bar = st.progress(0, text="æº–å‚™ä¸­...")
        final_report_data = []
        try:
            total_batches = math.ceil(len(uploaded_files) / BATCH_SIZE)
            for i in range(0, len(uploaded_files), BATCH_SIZE):
                current_batch_num = (i // BATCH_SIZE) + 1
                progress_text = f"å†™çœŸã‚’åˆ†æä¸­... (ãƒãƒƒãƒ {current_batch_num}/{total_batches})"
                progress_bar.progress(i / len(uploaded_files), text=progress_text)

                file_batch = uploaded_files[i:i + BATCH_SIZE]
                filenames = [f.name for f in file_batch]
                prompt = create_report_prompt(filenames)
                
                response_text = generate_ai_report(model, file_batch, prompt)
                batch_report_data = parse_json_response(response_text)
                
                if batch_report_data:
                    final_report_data.extend(batch_report_data)
                else:
                    raise Exception("AIã‹ã‚‰ã®å¿œç­”ã®è§£æã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
            
            progress_bar.progress(1.0, text="åˆ†æå®Œäº†ï¼")
            
            st.session_state.files_dict = {f.name: f for f in uploaded_files}
            st.session_state.report_payload = {
                "title": report_title,
                "date": survey_date.strftime('%Yå¹´%mæœˆ%dæ—¥'),
                "report_data": final_report_data
            }
        except Exception as e:
            st.error(f"åˆ†æå‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        finally:
            st.session_state.processing = False
            st.rerun()

if __name__ == "__main__":
    main()
