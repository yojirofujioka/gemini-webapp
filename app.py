import streamlit as st
import vertexai
from vertexai.generative_models import GenerativeModel, Part
import json
import re
from google.oauth2 import service_account
from datetime import date
import zlib
import base64

# ----------------------------------------------------------------------
# 1. Page Configuration
# ----------------------------------------------------------------------
st.set_page_config(
    page_title="AIãƒªãƒ•ã‚©ãƒ¼ãƒ ç®‡æ‰€åˆ†æãƒ¬ãƒãƒ¼ãƒˆ",
    page_icon="ğŸ ",
    layout="wide"
)

# ----------------------------------------------------------------------
# 2. GCP and Model Initialization
# ----------------------------------------------------------------------
@st.cache_resource
def initialize_vertexai():
    try:
        gcp_secrets = st.secrets["gcp"]
        service_account_info = json.loads(gcp_secrets["gcp_service_account"])
        credentials = service_account.Credentials.from_service_account_info(service_account_info)
        vertexai.init(project=gcp_secrets["project_id"], location="asia-northeast1", credentials=credentials)
        return GenerativeModel("gemini-1.5-pro")
    except Exception as e:
        st.error(f"GCPã®èªè¨¼ã¾ãŸã¯Vertex AIã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        return None

# ----------------------------------------------------------------------
# 3. Custom CSS for Professional Design
# ----------------------------------------------------------------------
def inject_custom_css():
    st.markdown("""
    <style>
        .report-container {
            background-color: #ffffff; color: #333333; border-radius: 8px;
            border: 1px solid #e0e0e0; padding: 2.5em 3.5em;
            box-shadow: 0 8px 30px rgba(0,0,0,0.05); margin: 2em 0;
        }
        .report-container h1 { color: #1F2937; font-size: 2.5em; border-bottom: 3px solid #D1D5DB; padding-bottom: 0.4em; }
        .report-container h2 { color: #1F2937; font-size: 1.8em; border-bottom: 2px solid #E5E7EB; padding-bottom: 0.3em; margin-top: 2em; }
        .report-container hr { border: 1px solid #e0e0e0; margin: 2.5em 0; }
        .photo-section { page-break-inside: avoid !important; padding-top: 2rem; margin-top: 2rem; border-top: 1px solid #e0e0e0; }
        .report-container .photo-section:first-of-type { border-top: none; padding-top: 0; margin-top: 0; }
        .photo-section h3 { color: #374151; font-size: 1.4em; margin: 0 0 1em 0; font-weight: 600; }
        .priority-badge { display: inline-block; padding: 0.3em 0.9em; border-radius: 15px; font-weight: 600; color: white; font-size: 0.9em; margin-left: 10px; }
        .priority-high { background-color: #DC2626; }
        .priority-medium { background-color: #F59E0B; }
        .priority-low { background-color: #3B82F6; }
        .no-print { /* This class will not be printed */ }
        @media print {
            .no-print { display: none !important; }
            .stApp > header, .stApp > footer, .stToolbar, #stDecoration { display: none !important; }
            body { background-color: #ffffff !important; }
            .report-container { box-shadow: none; border: 1px solid #ccc; padding: 1em; margin: 0; }
        }
    </style>
    """, unsafe_allow_html=True)

# ----------------------------------------------------------------------
# 4. Core AI and Data Handling Functions
# ----------------------------------------------------------------------
def create_report_prompt(filenames):
    file_list_str = "\n".join([f"- {name}" for name in filenames])
    return f"""
    ã‚ãªãŸã¯ã€æ—¥æœ¬ã®ãƒªãƒ•ã‚©ãƒ¼ãƒ ãƒ»åŸçŠ¶å›å¾©å·¥äº‹ã‚’å°‚é–€ã¨ã™ã‚‹ã€çµŒé¨“è±Šå¯Œãªç¾å ´ç›£ç£ã§ã™ã€‚ã‚ãªãŸã®ä»•äº‹ã¯ã€æä¾›ã•ã‚ŒãŸç¾å ´å†™çœŸã‚’åˆ†æã—ã€ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«æå‡ºã™ã‚‹ãŸã‚ã®ã€ä¸å¯§ã§åˆ†ã‹ã‚Šã‚„ã™ã„ä¿®ç¹•ææ¡ˆãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã™ã‚‹ã“ã¨ã§ã™ã€‚ä»¥ä¸‹ã®å†™çœŸï¼ˆãƒ•ã‚¡ã‚¤ãƒ«åã¨å…±ã«æç¤ºï¼‰ã‚’ä¸€æšãšã¤è©³ç´°ã«ç¢ºèªã—ã€ä¿®ç¹•ã‚„äº¤æ›ãŒå¿…è¦ã¨æ€ã‚ã‚Œã‚‹ç®‡æ‰€ã‚’ã™ã¹ã¦ç‰¹å®šã—ã¦ãã ã•ã„ã€‚ç‰¹å®šã—ãŸå„ç®‡æ‰€ã«ã¤ã„ã¦ã€ä»¥ä¸‹ã®JSONå½¢å¼ã§å ±å‘Šæ›¸ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
    **æœ€é‡è¦**: ã‚ãªãŸã®å‡ºåŠ›ã¯ã€ç´”ç²‹ãªJSONæ–‡å­—åˆ—ã®ã¿ã§ãªã‘ã‚Œã°ãªã‚Šã¾ã›ã‚“ã€‚èª¬æ˜æ–‡ã‚„ ```json ... ``` ã®ã‚ˆã†ãªãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ã¯çµ¶å¯¾ã«å«ã‚ãªã„ã§ãã ã•ã„ã€‚
    **JSONã®æ§‹é€ **:
    å‡ºåŠ›ã¯ã€JSONã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ãƒªã‚¹ãƒˆå½¢å¼ `[ ... ]` ã¨ã—ã¦ãã ã•ã„ã€‚å„ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã¯1æšã®å†™çœŸã«å¯¾å¿œã—ã¾ã™ã€‚
    å„å†™çœŸã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«ã¯ã€ä»¥ä¸‹ã®ã‚­ãƒ¼ã‚’å«ã‚ã¦ãã ã•ã„ã€‚
    - "file_name": (string) åˆ†æå¯¾è±¡ã®å†™çœŸã®ãƒ•ã‚¡ã‚¤ãƒ«åã€‚
    - "findings": (array) ãã®å†™çœŸã‹ã‚‰è¦‹ã¤ã‹ã£ãŸæŒ‡æ‘˜äº‹é …ã®ãƒªã‚¹ãƒˆã€‚æŒ‡æ‘˜ãŒãªã„å ´åˆã¯ç©ºã®ãƒªã‚¹ãƒˆ `[]` ã¨ã—ã¦ãã ã•ã„ã€‚
    - "observation": (string) ã€é‡è¦ã€‘"findings"ãŒç©ºã®å ´åˆã«ã®ã¿ã€å†™çœŸã‹ã‚‰èª­ã¿å–ã‚Œã‚‹å®¢è¦³çš„ãªæƒ…å ±ã‚’è¨˜è¿°ã—ã¦ãã ã•ã„ï¼ˆä¾‹ï¼šã€ŒTOTOè£½ãƒˆã‚¤ãƒ¬ã€å‹ç•ªTCF8GM23ã€‚ç›®ç«‹ã£ãŸå‚·ã‚„æ±šã‚Œãªã—ã€‚ã€ï¼‰ã€‚"findings"ãŒã‚ã‚‹å ´åˆã¯ç©ºæ–‡å­—åˆ— `""` ã¨ã—ã¦ãã ã•ã„ã€‚
    "findings" é…åˆ—ã®å„æŒ‡æ‘˜äº‹é …ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«ã¯ã€ä»¥ä¸‹ã®ã‚­ãƒ¼ã‚’å«ã‚ã¦ãã ã•ã„ã€‚
    - "location": (string) æŒ‡æ‘˜ç®‡æ‰€ã®å…·ä½“çš„ãªå ´æ‰€ã€‚
    - "current_state": (string) ç¾çŠ¶ã®å®¢è¦³çš„ãªèª¬æ˜ã€‚
    - "suggested_work": (string) ææ¡ˆã™ã‚‹å·¥äº‹å†…å®¹ã€‚
    - "priority": (string) å·¥äº‹ã®ç·Šæ€¥åº¦ã‚’ã€Œé«˜ã€ã€Œä¸­ã€ã€Œä½ã€ã®3æ®µéšã§è©•ä¾¡ã€‚
    - "notes": (string) ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã¸ã®è£œè¶³äº‹é …ã€‚
    ---
    åˆ†æå¯¾è±¡ã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆ: {file_list_str}
    ---
    ãã‚Œã§ã¯ã€ä»¥ä¸‹ã®å†™çœŸã®åˆ†æã‚’é–‹å§‹ã—ã¦ãã ã•ã„ã€‚
    """

def generate_ai_report(model, uploaded_files, prompt):
    image_parts = [Part.from_data(f.getvalue(), mime_type=f.type) for f in uploaded_files]
    response = model.generate_content([prompt] + image_parts)
    return response.text

def parse_json_response(text):
    match = re.search(r'```(json)?\s*(.*?)\s*```', text, re.DOTALL)
    json_str = match.group(2) if match else text
    try:
        return json.loads(json_str)
    except json.JSONDecodeError:
        st.error("AIã®å¿œç­”ã‚’JSONã¨ã—ã¦è§£æã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
        st.info("AIã‹ã‚‰ã®ç”Ÿã®å¿œç­”:"); st.code(text, language="text")
        return None

def encode_report_data(data):
    """Compresses and encodes report data for URL sharing."""
    json_str = json.dumps(data)
    compressed = zlib.compress(json_str.encode('utf-8'))
    return base64.urlsafe_b64encode(compressed).decode('utf-8')

def decode_report_data(encoded_data):
    """Decodes and decompresses report data from a URL."""
    try:
        compressed = base64.urlsafe_b64decode(encoded_data)
        json_str = zlib.decompress(compressed).decode('utf-8')
        return json.loads(json_str)
    except Exception:
        return None

# ----------------------------------------------------------------------
# 5. Report Display Functions
# ----------------------------------------------------------------------
def display_finding_content(finding):
    priority = finding.get('priority', 'N/A')
    p_class = {"é«˜": "high", "ä¸­": "medium", "ä½": "low"}.get(priority, "")
    st.markdown(f"**æŒ‡æ‘˜ç®‡æ‰€: {finding.get('location', 'N/A')}** <span class='priority-badge priority-{p_class}'>ç·Šæ€¥åº¦: {priority}</span>", unsafe_allow_html=True)
    st.markdown(f"- **ç¾çŠ¶:** {finding.get('current_state', 'N/A')}")
    st.markdown(f"- **ææ¡ˆå·¥äº‹:** {finding.get('suggested_work', 'N/A')}")
    if finding.get('notes'):
        st.markdown(f"- **å‚™è€ƒ:** {finding.get('notes', 'N/A')}")

def display_full_report(report_payload, files_dict=None):
    report_data = report_payload.get('report_data', [])
    report_title = report_payload.get('title', '')
    survey_date = report_payload.get('date', '')

    st.markdown('<div class="report-container">', unsafe_allow_html=True)
    
    # Header and Summary
    st.markdown(f"<h1>ç¾å ´åˆ†æãƒ¬ãƒãƒ¼ãƒˆ</h1>", unsafe_allow_html=True)
    c1, c2 = st.columns(2)
    c1.markdown(f"**ç‰©ä»¶åãƒ»æ¡ˆä»¶å:**<br>{report_title or 'ï¼ˆæœªè¨­å®šï¼‰'}", unsafe_allow_html=True)
    c2.markdown(f"**èª¿æŸ»æ—¥:**<br>{survey_date}", unsafe_allow_html=True)
    st.markdown("<hr>", unsafe_allow_html=True)
    st.markdown("<h2>ğŸ“Š åˆ†æçµæœã‚µãƒãƒªãƒ¼</h2>", unsafe_allow_html=True)
    total_findings = sum(len(item.get("findings", [])) for item in report_data)
    high_priority_count = sum(1 for item in report_data for f in item.get("findings", []) if f.get("priority") == "é«˜")
    m1, m2, m3 = st.columns(3)
    m1.metric("åˆ†æå†™çœŸæšæ•°", f"{len(report_data)} æš")
    m2.metric("ç·æŒ‡æ‘˜ä»¶æ•°", f"{total_findings} ä»¶")
    m3.metric("ç·Šæ€¥åº¦ã€Œé«˜ã€ã®ä»¶æ•°", f"{high_priority_count} ä»¶")
    st.markdown("<hr>", unsafe_allow_html=True)
    
    # Detailed Analysis
    st.markdown("<h2>ğŸ“‹ è©³ç´°åˆ†æçµæœ</h2>", unsafe_allow_html=True)
    for i, item in enumerate(report_data):
        st.markdown('<div class="photo-section">', unsafe_allow_html=True)
        st.markdown(f"<h3>{i + 1}. å†™çœŸãƒ•ã‚¡ã‚¤ãƒ«: {item.get('file_name', '')}</h3>", unsafe_allow_html=True)
        
        has_image = files_dict and item.get('file_name') in files_dict
        col1, col2 = st.columns([2, 3] if has_image else [0.01, 1]) # Adjust columns if no image

        if has_image:
            with col1:
                st.image(files_dict[item['file_name']], use_container_width=True)
        
        with col2:
            findings = item.get("findings", [])
            if findings:
                for finding in findings:
                    display_finding_content(finding)
            elif item.get("observation"):
                st.info(f"**ã€AIã«ã‚ˆã‚‹æ‰€è¦‹ã€‘**\n\n{item['observation']}")
            else:
                st.success("âœ… ç‰¹ã«ä¿®ç¹•ãŒå¿…è¦ãªç®‡æ‰€ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        st.markdown('</div>', unsafe_allow_html=True)
    
    st.markdown('</div>', unsafe_allow_html=True)

# ----------------------------------------------------------------------
# 6. Main Application Logic
# ----------------------------------------------------------------------
def main():
    inject_custom_css()
    model = initialize_vertexai()
    
    # Check if viewing a shared report from URL
    if "report" in st.query_params:
        report_payload = decode_report_data(st.query_params["report"])
        if report_payload:
            # The original user will have images in session_state, a shared user will not.
            files_dict = st.session_state.get("uploaded_files_dict")
            
            st.markdown('<div class="no-print">', unsafe_allow_html=True)
            st.success("ãƒ¬ãƒãƒ¼ãƒˆè¡¨ç¤ºä¸­")
            st.info("ã“ã®ãƒšãƒ¼ã‚¸ã®URLã‚’å…±æœ‰ã§ãã¾ã™ã€‚ãƒ–ãƒ©ã‚¦ã‚¶ã®å°åˆ·æ©Ÿèƒ½ï¼ˆCtrl+Pï¼‰ã§PDFåŒ–ã—ã¦ãã ã•ã„ã€‚")
            if st.button("æ–°ã—ã„ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã™ã‚‹"):
                st.query_params.clear()
            st.markdown('</div>', unsafe_allow_html=True)

            display_full_report(report_payload, files_dict)
        else:
            st.error("ãƒ¬ãƒãƒ¼ãƒˆã®URLãŒç„¡åŠ¹ã§ã™ã€‚")
            if st.button("ãƒ›ãƒ¼ãƒ ã«æˆ»ã‚‹"):
                st.query_params.clear()
    
    # Default view: Show the form to create a new report
    else:
        st.markdown('<div class="no-print">', unsafe_allow_html=True)
        st.title("ğŸ“· AIãƒªãƒ•ã‚©ãƒ¼ãƒ ç®‡æ‰€åˆ†æï¼†å ±å‘Šæ›¸ä½œæˆ")
        st.markdown("ç¾å ´å†™çœŸã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã¨ã€AIãŒã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆå‘ã‘ã®ä¿®ç¹•ææ¡ˆãƒ¬ãƒãƒ¼ãƒˆã‚’è‡ªå‹•ä½œæˆã—ã¾ã™ã€‚")

        if not model:
            st.warning("AIãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸã€‚"); st.stop()
        
        with st.form("report_form"):
            st.subheader("1. ãƒ¬ãƒãƒ¼ãƒˆæƒ…å ±å…¥åŠ›")
            report_title = st.text_input("ç‰©ä»¶åãƒ»æ¡ˆä»¶å", "ï¼ˆä¾‹ï¼‰ã€‡ã€‡ãƒ“ãƒ« 301å·å®¤ åŸçŠ¶å›å¾©å·¥äº‹")
            survey_date = st.date_input("èª¿æŸ»æ—¥", date.today())
            
            st.subheader("2. å†™çœŸã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
            uploaded_files = st.file_uploader("åˆ†æã—ãŸã„å†™çœŸã‚’é¸æŠ", type=["png", "jpg", "jpeg"], accept_multiple_files=True)
            
            submitted = st.form_submit_button("ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã™ã‚‹", type="primary", use_container_width=True)

        if submitted:
            if not uploaded_files:
                st.warning("åˆ†æã‚’é–‹å§‹ã™ã‚‹ã«ã¯ã€å†™çœŸã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
            else:
                with st.spinner("AIãŒå†™çœŸã‚’åˆ†æã—ã€ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆä¸­ã§ã™â€¦"):
                    try:
                        prompt = create_report_prompt([f.name for f in uploaded_files])
                        response_text = generate_ai_report(model, uploaded_files, prompt)
                        report_data = parse_json_response(response_text)
                        
                        if report_data:
                            # For the original user, store images in session state
                            st.session_state.uploaded_files_dict = {f.name: f for f in uploaded_files}
                            
                            # Create payload for URL (text-only data)
                            report_payload = {
                                "title": report_title,
                                "date": survey_date.strftime('%Yå¹´%mæœˆ%dæ—¥'),
                                "report_data": report_data
                            }
                            # Encode and set as query parameter to redirect
                            st.query_params["report"] = encode_report_data(report_payload)
                        else:
                            st.error("ãƒ¬ãƒãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
                    except Exception as e:
                        st.error(f"åˆ†æä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

        st.markdown('</div>', unsafe_allow_html=True)

if __name__ == "__main__":
    main()
