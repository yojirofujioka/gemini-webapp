import streamlit as st
import vertexai
from vertexai.generative_models import GenerativeModel, Part
import json
import re
from google.oauth2 import service_account
from datetime import date
import zlib
import base64
import math

# ----------------------------------------------------------------------
# 1. è¨­å®šã¨å®šæ•°
# ----------------------------------------------------------------------
st.set_page_config(
    page_title="AIãƒªãƒ•ã‚©ãƒ¼ãƒ ç®‡æ‰€åˆ†æãƒ¬ãƒãƒ¼ãƒˆ",
    page_icon="ğŸ ",
    layout="wide"
)
BATCH_SIZE = 10 # ä¸€åº¦ã«AIã«é€ä¿¡ã™ã‚‹å†™çœŸã®æšæ•°

# ----------------------------------------------------------------------
# 2. ãƒ‡ã‚¶ã‚¤ãƒ³ã¨GCPåˆæœŸåŒ–
# ----------------------------------------------------------------------
def inject_custom_css():
    """ãƒ¬ãƒãƒ¼ãƒˆãƒ‡ã‚¶ã‚¤ãƒ³ã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã®ã‚«ã‚¹ã‚¿ãƒ CSSã‚’æ³¨å…¥ã™ã‚‹ã€‚"""
    st.markdown("""
    <style>
        .report-container { background-color: #ffffff; color: #333333; border-radius: 8px; border: 1px solid #e0e0e0; padding: 2.5em 3.5em; box-shadow: 0 8px 30px rgba(0,0,0,0.05); margin: 2em 0; }
        .report-container h1 { color: #1F2937; font-size: 2.5em; border-bottom: 3px solid #D1D5DB; padding-bottom: 0.4em; }
        .report-container h2 { color: #1F2937; font-size: 1.8em; border-bottom: 2px solid #E5E7EB; padding-bottom: 0.3em; margin-top: 2em; }
        .report-container hr { border: 1px solid #e0e0e0; margin: 2.5em 0; }
        .photo-section { page-break-inside: avoid !important; padding-top: 2rem; margin-top: 2rem; border-top: 1px solid #e0e0e0; }
        .report-container .photo-section:first-of-type { border-top: none; padding-top: 0; margin-top: 0; }
        .photo-section h3 { color: #374151; font-size: 1.4em; margin: 0 0 1em 0; font-weight: 600; }
        .priority-badge { display: inline-block; padding: 0.3em 0.9em; border-radius: 15px; font-weight: 600; color: white; font-size: 0.9em; margin-left: 10px; }
        .priority-high { background-color: #DC2626; }
        .priority-medium { background-color: #F59E0B; }
        .priority-low { background-color: #3B82F6; }
        .no-print { /* ã“ã®ã‚¯ãƒ©ã‚¹ã‚’æŒã¤è¦ç´ ã¯å°åˆ·ã—ãªã„ */ }
        @media print {
            .no-print { display: none !important; }
            .stApp > header, .stApp > footer, .stToolbar, #stDecoration { display: none !important; }
            body { background-color: #ffffff !important; }
            .report-container { box-shadow: none; border: 1px solid #ccc; padding: 1em; margin: 0; }
        }
    </style>
    """, unsafe_allow_html=True)

@st.cache_resource
def initialize_vertexai():
    try:
        gcp_secrets = st.secrets["gcp"]
        service_account_info = json.loads(gcp_secrets["gcp_service_account"])
        credentials = service_account.Credentials.from_service_account_info(service_account_info)
        vertexai.init(project=gcp_secrets["project_id"], location="asia-northeast1", credentials=credentials)
        return GenerativeModel("gemini-1.5-pro")
    except Exception as e:
        st.error(f"GCPã®èªè¨¼ã¾ãŸã¯Vertex AIã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        return None

# ----------------------------------------------------------------------
# 3. AIã¨ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã®é–¢æ•°
# ----------------------------------------------------------------------
def create_report_prompt(filenames):
    file_list_str = "\n".join([f"- {name}" for name in filenames])
    return f"""
    ã‚ãªãŸã¯ã€æ—¥æœ¬ã®ãƒªãƒ•ã‚©ãƒ¼ãƒ ãƒ»åŸçŠ¶å›å¾©å·¥äº‹ã‚’å°‚é–€ã¨ã™ã‚‹ã€çµŒé¨“è±Šå¯Œãªç¾å ´ç›£ç£ã§ã™ã€‚ã‚ãªãŸã®ä»•äº‹ã¯ã€æä¾›ã•ã‚ŒãŸç¾å ´å†™çœŸã‚’åˆ†æã—ã€ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«æå‡ºã™ã‚‹ãŸã‚ã®ã€ä¸å¯§ã§åˆ†ã‹ã‚Šã‚„ã™ã„ä¿®ç¹•ææ¡ˆãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã™ã‚‹ã“ã¨ã§ã™ã€‚ä»¥ä¸‹ã®å†™çœŸï¼ˆãƒ•ã‚¡ã‚¤ãƒ«åã¨å…±ã«æç¤ºï¼‰ã‚’ä¸€æšãšã¤è©³ç´°ã«ç¢ºèªã—ã€ä¿®ç¹•ã‚„äº¤æ›ãŒå¿…è¦ã¨æ€ã‚ã‚Œã‚‹ç®‡æ‰€ã‚’ã™ã¹ã¦ç‰¹å®šã—ã¦ãã ã•ã„ã€‚ç‰¹å®šã—ãŸå„ç®‡æ‰€ã«ã¤ã„ã¦ã€ä»¥ä¸‹ã®JSONå½¢å¼ã§å ±å‘Šæ›¸ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
    **æœ€é‡è¦**: ã‚ãªãŸã®å‡ºåŠ›ã¯ã€ç´”ç²‹ãªJSONæ–‡å­—åˆ—ã®ã¿ã§ãªã‘ã‚Œã°ãªã‚Šã¾ã›ã‚“ã€‚èª¬æ˜æ–‡ã‚„ ```json ... ``` ã®ã‚ˆã†ãªãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ã¯çµ¶å¯¾ã«å«ã‚ãªã„ã§ãã ã•ã„ã€‚
    **JSONã®æ§‹é€ **:
    å‡ºåŠ›ã¯ã€JSONã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ãƒªã‚¹ãƒˆå½¢å¼ `[ ... ]` ã¨ã—ã¦ãã ã•ã„ã€‚å„ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã¯1æšã®å†™çœŸã«å¯¾å¿œã—ã¾ã™ã€‚
    å„å†™çœŸã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«ã¯ã€ä»¥ä¸‹ã®ã‚­ãƒ¼ã‚’å«ã‚ã¦ãã ã•ã„ã€‚
    - "file_name": (string) åˆ†æå¯¾è±¡ã®å†™çœŸã®ãƒ•ã‚¡ã‚¤ãƒ«åã€‚
    - "findings": (array) ãã®å†™çœŸã‹ã‚‰è¦‹ã¤ã‹ã£ãŸæŒ‡æ‘˜äº‹é …ã®ãƒªã‚¹ãƒˆã€‚æŒ‡æ‘˜ãŒãªã„å ´åˆã¯ç©ºã®ãƒªã‚¹ãƒˆ `[]` ã¨ã—ã¦ãã ã•ã„ã€‚
    - "observation": (string) ã€é‡è¦ã€‘"findings"ãŒç©ºã®å ´åˆã«ã®ã¿ã€å†™çœŸã‹ã‚‰èª­ã¿å–ã‚Œã‚‹å®¢è¦³çš„ãªæƒ…å ±ã‚’è¨˜è¿°ã—ã¦ãã ã•ã„ï¼ˆä¾‹ï¼šã€ŒTOTOè£½ãƒˆã‚¤ãƒ¬ã€å‹ç•ªTCF8GM23ã€‚ç›®ç«‹ã£ãŸå‚·ã‚„æ±šã‚Œãªã—ã€‚ã€ï¼‰ã€‚"findings"ãŒã‚ã‚‹å ´åˆã¯ç©ºæ–‡å­—åˆ— `""` ã¨ã—ã¦ãã ã•ã„ã€‚
    "findings" é…åˆ—ã®å„æŒ‡æ‘˜äº‹é …ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«ã¯ã€ä»¥ä¸‹ã®ã‚­ãƒ¼ã‚’å«ã‚ã¦ãã ã•ã„ã€‚
    - "location": (string) æŒ‡æ‘˜ç®‡æ‰€ã®å…·ä½“çš„ãªå ´æ‰€ã€‚
    - "current_state": (string) ç¾çŠ¶ã®å®¢è¦³çš„ãªèª¬æ˜ã€‚
    - "suggested_work": (string) ææ¡ˆã™ã‚‹å·¥äº‹å†…å®¹ã€‚
    - "priority": (string) å·¥äº‹ã®ç·Šæ€¥åº¦ã‚’ã€Œé«˜ã€ã€Œä¸­ã€ã€Œä½ã€ã®3æ®µéšã§è©•ä¾¡ã€‚
    - "notes": (string) ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã¸ã®è£œè¶³äº‹é …ã€‚
    ---
    åˆ†æå¯¾è±¡ã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆ: {file_list_str}
    ---
    ãã‚Œã§ã¯ã€ä»¥ä¸‹ã®å†™çœŸã®åˆ†æã‚’é–‹å§‹ã—ã¦ãã ã•ã„ã€‚
    """

def generate_ai_report(model, file_batch, prompt):
    image_parts = [Part.from_data(f.getvalue(), mime_type=f.type) for f in file_batch]
    response = model.generate_content([prompt] + image_parts)
    return response.text

def parse_json_response(text):
    match = re.search(r'```(json)?\s*(.*?)\s*```', text, re.DOTALL)
    json_str = match.group(2) if match else text
    try:
        return json.loads(json_str)
    except json.JSONDecodeError:
        st.error("AIã®å¿œç­”ã‚’JSONã¨ã—ã¦è§£æã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
        st.info("AIã‹ã‚‰ã®ç”Ÿã®å¿œç­”:"); st.code(text, language="text")
        return None

def encode_report_data(data):
    json_str = json.dumps(data)
    compressed = zlib.compress(json_str.encode('utf-8'))
    return base64.urlsafe_b64encode(compressed).decode('utf-8')

def decode_report_data(encoded_data):
    try:
        compressed = base64.urlsafe_b64decode(encoded_data)
        json_str = zlib.decompress(compressed).decode('utf-8')
        return json.loads(json_str)
    except Exception:
        return None

# ----------------------------------------------------------------------
# 4. ãƒ¬ãƒãƒ¼ãƒˆè¡¨ç¤ºã®é–¢æ•°
# ----------------------------------------------------------------------
def display_finding_content(finding):
    priority = finding.get('priority', 'N/A')
    p_class = {"é«˜": "high", "ä¸­": "medium", "ä½": "low"}.get(priority, "")
    st.markdown(f"**æŒ‡æ‘˜ç®‡æ‰€: {finding.get('location', 'N/A')}** <span class='priority-badge priority-{p_class}'>ç·Šæ€¥åº¦: {priority}</span>", unsafe_allow_html=True)
    st.markdown(f"- **ç¾çŠ¶:** {finding.get('current_state', 'N/A')}")
    st.markdown(f"- **ææ¡ˆå·¥äº‹:** {finding.get('suggested_work', 'N/A')}")
    if finding.get('notes'):
        st.markdown(f"- **å‚™è€ƒ:** {finding.get('notes', 'N/A')}")

def display_full_report(report_payload, files_dict=None):
    report_data = report_payload.get('report_data', [])
    report_title = report_payload.get('title', '')
    survey_date = report_payload.get('date', '')

    st.markdown('<div class="report-container">', unsafe_allow_html=True)
    
    st.markdown(f"<h1>ç¾å ´åˆ†æãƒ¬ãƒãƒ¼ãƒˆ</h1>", unsafe_allow_html=True)
    c1, c2 = st.columns(2); c1.markdown(f"**ç‰©ä»¶åãƒ»æ¡ˆä»¶å:**<br>{report_title or 'ï¼ˆæœªè¨­å®šï¼‰'}", unsafe_allow_html=True); c2.markdown(f"**èª¿æŸ»æ—¥:**<br>{survey_date}", unsafe_allow_html=True)
    st.markdown("<hr>", unsafe_allow_html=True)
    st.markdown("<h2>ğŸ“Š åˆ†æçµæœã‚µãƒãƒªãƒ¼</h2>", unsafe_allow_html=True)
    total_findings = sum(len(item.get("findings", [])) for item in report_data)
    high_priority_count = sum(1 for item in report_data for f in item.get("findings", []) if f.get("priority") == "é«˜")
    m1, m2, m3 = st.columns(3); m1.metric("åˆ†æå†™çœŸæšæ•°", f"{len(report_data)} æš"); m2.metric("ç·æŒ‡æ‘˜ä»¶æ•°", f"{total_findings} ä»¶"); m3.metric("ç·Šæ€¥åº¦ã€Œé«˜ã€ã®ä»¶æ•°", f"{high_priority_count} ä»¶")
    st.markdown("<hr>", unsafe_allow_html=True)
    
    st.markdown("<h2>ğŸ“‹ è©³ç´°åˆ†æçµæœ</h2>", unsafe_allow_html=True)
    for i, item in enumerate(report_data):
        st.markdown('<div class="photo-section">', unsafe_allow_html=True)
        st.markdown(f"<h3>{i + 1}. å†™çœŸãƒ•ã‚¡ã‚¤ãƒ«: {item.get('file_name', '')}</h3>", unsafe_allow_html=True)
        
        has_image = files_dict and item.get('file_name') in files_dict
        col1, col2 = st.columns([2, 3])
        
        with col1:
            if has_image:
                st.image(files_dict[item['file_name']], use_container_width=True)
            else:
                st.empty()
        
        with col2:
            findings = item.get("findings", [])
            if findings:
                for finding in findings:
                    display_finding_content(finding)
            elif item.get("observation"):
                st.info(f"**ã€AIã«ã‚ˆã‚‹æ‰€è¦‹ã€‘**\n\n{item['observation']}")
            else:
                st.success("âœ… ç‰¹ã«ä¿®ç¹•ãŒå¿…è¦ãªç®‡æ‰€ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        st.markdown('</div>', unsafe_allow_html=True)
    
    st.markdown('</div>', unsafe_allow_html=True)

# ----------------------------------------------------------------------
# 5. ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³
# ----------------------------------------------------------------------
def main():
    inject_custom_css()
    model = initialize_vertexai()

    if "report" in st.query_params:
        report_payload = decode_report_data(st.query_params["report"])
        if report_payload:
            st.markdown('<div class="no-print">', unsafe_allow_html=True)
            st.success("ãƒ¬ãƒãƒ¼ãƒˆè¡¨ç¤ºä¸­ï¼ˆå…±æœ‰ãƒ¢ãƒ¼ãƒ‰ï¼‰")
            st.info("ã“ã®ãƒšãƒ¼ã‚¸ã®URLã‚’ä»–è€…ã«å…±æœ‰ã§ãã¾ã™ã€‚ãƒ–ãƒ©ã‚¦ã‚¶ã®å°åˆ·æ©Ÿèƒ½ï¼ˆCtrl+Pï¼‰ã§PDFåŒ–ã—ã¦ãã ã•ã„ã€‚")
            if st.button("æ–°ã—ã„ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã™ã‚‹", key="new_from_shared"):
                st.session_state.clear()
                st.query_params.clear()
            st.markdown('</div>', unsafe_allow_html=True)
            display_full_report(report_payload)
        else:
            st.error("ãƒ¬ãƒãƒ¼ãƒˆã®URLãŒç„¡åŠ¹ã§ã™ã€‚")
            if st.button("ãƒ›ãƒ¼ãƒ ã«æˆ»ã‚‹"): st.query_params.clear()
        return

    # --- ãƒ¬ãƒãƒ¼ãƒˆä½œæˆç”»é¢ ---
    st.markdown('<div class="no-print">', unsafe_allow_html=True)
    if 'processing' not in st.session_state:
        st.session_state.processing = False

    # ãƒ¬ãƒãƒ¼ãƒˆä½œæˆä¸­ã¯ä½•ã‚‚ã—ãªã„
    if st.session_state.processing:
        return

    st.title("ğŸ“· AIãƒªãƒ•ã‚©ãƒ¼ãƒ ç®‡æ‰€åˆ†æï¼†å ±å‘Šæ›¸ä½œæˆ")
    st.markdown("ç¾å ´å†™çœŸã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã¨ã€AIãŒã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆå‘ã‘ã®ä¿®ç¹•ææ¡ˆãƒ¬ãƒãƒ¼ãƒˆã‚’è‡ªå‹•ä½œæˆã—ã¾ã™ã€‚")

    if not model:
        st.warning("AIãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸã€‚"); st.stop()
    
    with st.form("report_form"):
        st.subheader("1. ãƒ¬ãƒãƒ¼ãƒˆæƒ…å ±å…¥åŠ›")
        report_title = st.text_input("ç‰©ä»¶åãƒ»æ¡ˆä»¶å", "ï¼ˆä¾‹ï¼‰ã€‡ã€‡ãƒ“ãƒ« 301å·å®¤ åŸçŠ¶å›å¾©å·¥äº‹")
        survey_date = st.date_input("èª¿æŸ»æ—¥", date.today())
        
        st.subheader("2. å†™çœŸã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
        uploaded_files = st.file_uploader(
            "åˆ†æã—ãŸã„å†™çœŸã‚’é¸æŠ",
            type=["png", "jpg", "jpeg"],
            accept_multiple_files=True,
            key="file_uploader"
        )
        
        # â˜…ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰çŠ¶æ³ã®è¡¨ç¤º
        if uploaded_files:
            st.success(f"{len(uploaded_files)}ä»¶ã®å†™çœŸãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¾ã—ãŸã€‚")
        else:
            st.info("ã“ã“ã«å†™çœŸã‚’ãƒ‰ãƒ©ãƒƒã‚°ï¼†ãƒ‰ãƒ­ãƒƒãƒ—ã™ã‚‹ã‹ã€ã€ŒBrowse filesã€ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦é¸æŠã—ã¦ãã ã•ã„ã€‚")
        
        submitted = st.form_submit_button(
            "ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã™ã‚‹",
            type="primary",
            use_container_width=True,
            disabled=not uploaded_files # â˜…ãƒ•ã‚¡ã‚¤ãƒ«ãŒãªã‘ã‚Œã°éæ´»æ€§
        )

    if submitted:
        st.session_state.processing = True
        total_batches = math.ceil(len(uploaded_files) / BATCH_SIZE)
        progress_bar = st.progress(0, text="AIåˆ†æã®æº–å‚™ã‚’ã—ã¦ã„ã¾ã™...")
        
        final_report_data = []
        try:
            for i in range(0, len(uploaded_files), BATCH_SIZE):
                current_batch_num = (i // BATCH_SIZE) + 1
                progress_text = f"AIãŒå†™çœŸã‚’åˆ†æä¸­... (ãƒãƒƒãƒ {current_batch_num}/{total_batches})"
                progress_bar.progress(i / len(uploaded_files), text=progress_text)

                file_batch = uploaded_files[i:i + BATCH_SIZE]
                filenames = [f.name for f in file_batch]
                prompt = create_report_prompt(filenames)
                
                response_text = generate_ai_report(model, file_batch, prompt)
                batch_report_data = parse_json_response(response_text)
                
                if batch_report_data:
                    final_report_data.extend(batch_report_data)
                else:
                    st.error(f"ãƒãƒƒãƒ {current_batch_num} ã®åˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ã“ã®ãƒãƒƒãƒã¯ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã¾ã™ã€‚")
            
            progress_bar.progress(1.0, text="åˆ†æå®Œäº†ï¼ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆä¸­ã§ã™...")
            
            st.session_state.files_dict = {f.name: f for f in uploaded_files}
            report_payload = {
                "title": report_title,
                "date": survey_date.strftime('%Yå¹´%mæœˆ%dæ—¥'),
                "report_data": final_report_data
            }
            
            st.session_state.report_payload = report_payload
            st.query_params["report"] = encode_report_data(report_payload)
            
        except Exception as e:
            st.error(f"åˆ†æå‡¦ç†å…¨ä½“ã§äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        finally:
            st.session_state.processing = False
            progress_bar.empty()
            st.rerun() # çµæœè¡¨ç¤ºã®ãŸã‚ã«å†æç”»

    # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ãƒ¬ãƒãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Œã°è¡¨ç¤º
    if 'report_payload' in st.session_state:
        st.info("ğŸ’¡ ãƒ¬ãƒãƒ¼ãƒˆã‚’PDFã¨ã—ã¦ä¿å­˜ã™ã‚‹ã«ã¯ã€ãƒ–ãƒ©ã‚¦ã‚¶ã®å°åˆ·æ©Ÿèƒ½ï¼ˆCtrl+P ã¾ãŸã¯ Cmd+Pï¼‰ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚")
        st.info("â„¹ï¸ ã“ã®ãƒšãƒ¼ã‚¸ã®URLã‚’å…±æœ‰ã™ã‚‹ã¨ã€ãƒ†ã‚­ã‚¹ãƒˆã®ã¿ã®ãƒ¬ãƒãƒ¼ãƒˆãŒç›¸æ‰‹ã«è¡¨ç¤ºã•ã‚Œã¾ã™ã€‚")
        display_full_report(st.session_state.report_payload, st.session_state.files_dict)
        
    st.markdown('</div>', unsafe_allow_html=True)

if __name__ == "__main__":
    main()
