import streamlit as st
import vertexai
from vertexai.generative_models import GenerativeModel, Part
import json
import re
from google.oauth2 import service_account
from datetime import date
import math
import base64 # â˜…ã‚¨ãƒ©ãƒ¼ä¿®æ­£ã®ãŸã‚ã€å‰Šé™¤ã•ã‚Œã¦ã„ãŸbase64ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’å†ã‚¤ãƒ³ãƒãƒ¼ãƒˆ

# ----------------------------------------------------------------------
# 1. è¨­å®šã¨å®šæ•°
# ----------------------------------------------------------------------
st.set_page_config(
    page_title="AIãƒªãƒ•ã‚©ãƒ¼ãƒ ç®‡æ‰€åˆ†æãƒ¬ãƒãƒ¼ãƒˆ",
    page_icon="ğŸ ",
    layout="wide"
)
BATCH_SIZE = 10 # ä¸€åº¦ã«AIã«é€ä¿¡ã™ã‚‹å†™çœŸã®æšæ•°

# ----------------------------------------------------------------------
# 2. ãƒ‡ã‚¶ã‚¤ãƒ³ã¨GCPåˆæœŸåŒ–
# ----------------------------------------------------------------------
def inject_custom_css():
    """ãƒ¬ãƒãƒ¼ãƒˆãƒ‡ã‚¶ã‚¤ãƒ³ã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã®ã‚«ã‚¹ã‚¿ãƒ CSSã‚’æ³¨å…¥ã™ã‚‹ã€‚"""
    st.markdown("""
    <style>
        /* --- åŸºæœ¬çš„ãªãƒ¬ãƒãƒ¼ãƒˆã‚¹ã‚¿ã‚¤ãƒ« --- */
        .report-container { background-color: #ffffff; color: #333333; border-radius: 8px; border: 1px solid #e0e0e0; padding: 2.5em 3.5em; box-shadow: 0 8px 30px rgba(0,0,0,0.05); margin: 2em 0; }
        .report-container h1 { color: #1F2937; font-size: 2.5em; border-bottom: 3px solid #D1D5DB; padding-bottom: 0.4em; }
        .report-container h2 { color: #1F2937; font-size: 1.8em; border-bottom: 2px solid #E5E7EB; padding-bottom: 0.3em; margin-top: 2em; }
        .report-container hr { border: 1px solid #e0e0e0; margin: 2.5em 0; }
        .priority-badge { display: inline-block; padding: 0.3em 0.9em; border-radius: 15px; font-weight: 600; color: white; font-size: 0.9em; margin-left: 10px; }
        .priority-high { background-color: #DC2626; }
        .priority-medium { background-color: #F59E0B; }
        .priority-low { background-color: #3B82F6; }
        
        /* --- ç”»é¢è¡¨ç¤ºæ™‚ã®ã‚¹ã‚¿ã‚¤ãƒ« (1åˆ—è¡¨ç¤º) --- */
        .photo-section { border-top: 1px solid #e0e0e0; padding-top: 2rem; margin-top: 2rem; }
        .report-container .photo-section:first-of-type { border-top: none; padding-top: 0; margin-top: 0; }
        .photo-section h3 { color: #374151; font-size: 1.4em; margin: 0 0 1em 0; font-weight: 600; }
        .image-container img { max-height: 400px; width: auto; max-width: 100%; }

        /* --- å°åˆ·æ™‚ã®ã‚¹ã‚¿ã‚¤ãƒ« --- */
        @media print {
            .main > .block-container > div:nth-child(1) > div:nth-child(1) > div:not(.printable-report) { display: none !important; }
            .stApp > header, .stApp > footer, .stToolbar, #stDecoration { display: none !important; }
            body { background-color: #ffffff !important; }
            .printable-report { box-shadow: none; border: none; padding: 0; margin: 0; }
            .print-grid { display: grid; grid-template-columns: repeat(3, 1fr); gap: 20px; page-break-after: always; }
            .print-item { border: 1px solid #ccc; padding: 15px; border-radius: 8px; display: flex; flex-direction: column; page-break-inside: avoid; }
            .print-item h3 { font-size: 12px; margin: 0 0 10px 0; font-weight: bold; }
            .print-item .image-box { height: 180px; display: flex; align-items: center; justify-content: center; margin-bottom: 10px; overflow: hidden; }
            .print-item .image-box img { width: 100%; height: 100%; object-fit: contain; }
            .print-item .text-box { font-size: 10px; line-height: 1.4; }
            .print-item .priority-badge { font-size: 9px; padding: 2px 6px; }
        }
    </style>
    """, unsafe_allow_html=True)

@st.cache_resource
def initialize_vertexai():
    try:
        gcp_secrets = st.secrets["gcp"]
        service_account_info = json.loads(gcp_secrets["gcp_service_account"])
        credentials = service_account.Credentials.from_service_account_info(service_account_info)
        vertexai.init(project=gcp_secrets["project_id"], location="asia-northeast1", credentials=credentials)
        return GenerativeModel("gemini-1.5-pro")
    except Exception as e:
        st.error(f"GCPã®èªè¨¼ã¾ãŸã¯Vertex AIã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        return None

# ----------------------------------------------------------------------
# 3. AIã¨ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã®é–¢æ•°
# ----------------------------------------------------------------------
def create_report_prompt(filenames):
    file_list_str = "\n".join([f"- {name}" for name in filenames])
    return f"""
    ã‚ãªãŸã¯ã€æ—¥æœ¬ã®ãƒªãƒ•ã‚©ãƒ¼ãƒ ãƒ»åŸçŠ¶å›å¾©å·¥äº‹ã‚’å°‚é–€ã¨ã™ã‚‹ã€çµŒé¨“è±Šå¯Œãªç¾å ´ç›£ç£ã§ã™ã€‚ã‚ãªãŸã®ä»•äº‹ã¯ã€æä¾›ã•ã‚ŒãŸç¾å ´å†™çœŸã‚’åˆ†æã—ã€ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«æå‡ºã™ã‚‹ãŸã‚ã®ã€ä¸å¯§ã§åˆ†ã‹ã‚Šã‚„ã™ã„ä¿®ç¹•ææ¡ˆãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã™ã‚‹ã“ã¨ã§ã™ã€‚ä»¥ä¸‹ã®å†™çœŸï¼ˆãƒ•ã‚¡ã‚¤ãƒ«åã¨å…±ã«æç¤ºï¼‰ã‚’ä¸€æšãšã¤è©³ç´°ã«ç¢ºèªã—ã€ä¿®ç¹•ã‚„äº¤æ›ãŒå¿…è¦ã¨æ€ã‚ã‚Œã‚‹ç®‡æ‰€ã‚’ã™ã¹ã¦ç‰¹å®šã—ã¦ãã ã•ã„ã€‚ç‰¹å®šã—ãŸå„ç®‡æ‰€ã«ã¤ã„ã¦ã€ä»¥ä¸‹ã®JSONå½¢å¼ã§å ±å‘Šæ›¸ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
    **æœ€é‡è¦**: ã‚ãªãŸã®å‡ºåŠ›ã¯ã€ç´”ç²‹ãªJSONæ–‡å­—åˆ—ã®ã¿ã§ãªã‘ã‚Œã°ãªã‚Šã¾ã›ã‚“ã€‚èª¬æ˜æ–‡ã‚„ ```json ... ``` ã®ã‚ˆã†ãªãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ã¯çµ¶å¯¾ã«å«ã‚ãªã„ã§ãã ã•ã„ã€‚
    **JSONã®æ§‹é€ **:
    å‡ºåŠ›ã¯ã€JSONã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ãƒªã‚¹ãƒˆå½¢å¼ `[ ... ]` ã¨ã—ã¦ãã ã•ã„ã€‚å„ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã¯1æšã®å†™çœŸã«å¯¾å¿œã—ã¾ã™ã€‚
    å„å†™çœŸã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«ã¯ã€ä»¥ä¸‹ã®ã‚­ãƒ¼ã‚’å«ã‚ã¦ãã ã•ã„ã€‚
    - "file_name": (string) åˆ†æå¯¾è±¡ã®å†™çœŸã®ãƒ•ã‚¡ã‚¤ãƒ«åã€‚
    - "findings": (array) ãã®å†™çœŸã‹ã‚‰è¦‹ã¤ã‹ã£ãŸæŒ‡æ‘˜äº‹é …ã®ãƒªã‚¹ãƒˆã€‚æŒ‡æ‘˜ãŒãªã„å ´åˆã¯ç©ºã®ãƒªã‚¹ãƒˆ `[]` ã¨ã—ã¦ãã ã•ã„ã€‚
    - "observation": (string) ã€é‡è¦ã€‘"findings"ãŒç©ºã®å ´åˆã«ã®ã¿ã€å†™çœŸã‹ã‚‰èª­ã¿å–ã‚Œã‚‹å®¢è¦³çš„ãªæƒ…å ±ã‚’è¨˜è¿°ã—ã¦ãã ã•ã„ï¼ˆä¾‹ï¼šã€ŒTOTOè£½ãƒˆã‚¤ãƒ¬ã€å‹ç•ªTCF8GM23ã€‚ç›®ç«‹ã£ãŸå‚·ã‚„æ±šã‚Œãªã—ã€‚ã€ï¼‰ã€‚"findings"ãŒã‚ã‚‹å ´åˆã¯ç©ºæ–‡å­—åˆ— `""` ã¨ã—ã¦ãã ã•ã„ã€‚
    "findings" é…åˆ—ã®å„æŒ‡æ‘˜äº‹é …ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«ã¯ã€ä»¥ä¸‹ã®ã‚­ãƒ¼ã‚’å«ã‚ã¦ãã ã•ã„ã€‚
    - "location": (string) æŒ‡æ‘˜ç®‡æ‰€ã®å…·ä½“çš„ãªå ´æ‰€ã€‚
    - "current_state": (string) ç¾çŠ¶ã®å®¢è¦³çš„ãªèª¬æ˜ã€‚
    - "suggested_work": (string) ææ¡ˆã™ã‚‹å·¥äº‹å†…å®¹ã€‚
    - "priority": (string) å·¥äº‹ã®ç·Šæ€¥åº¦ã‚’ã€Œé«˜ã€ã€Œä¸­ã€ã€Œä½ã€ã®3æ®µéšã§è©•ä¾¡ã€‚
    - "notes": (string) ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã¸ã®è£œè¶³äº‹é …ã€‚
    ---
    åˆ†æå¯¾è±¡ã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆ: {file_list_str}
    ---
    ãã‚Œã§ã¯ã€ä»¥ä¸‹ã®å†™çœŸã®åˆ†æã‚’é–‹å§‹ã—ã¦ãã ã•ã„ã€‚
    """

def generate_ai_report(model, file_batch, prompt):
    image_parts = [Part.from_data(f.getvalue(), mime_type=f.type) for f in file_batch]
    response = model.generate_content([prompt] + image_parts)
    return response.text

def parse_json_response(text):
    match = re.search(r'```(json)?\s*(.*?)\s*```', text, re.DOTALL)
    json_str = match.group(2) if match else text
    try:
        return json.loads(json_str)
    except json.JSONDecodeError:
        st.error("AIã®å¿œç­”ã‚’JSONã¨ã—ã¦è§£æã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
        st.info("AIã‹ã‚‰ã®ç”Ÿã®å¿œç­”:"); st.code(text, language="text")
        return None

# ----------------------------------------------------------------------
# 4. ãƒ¬ãƒãƒ¼ãƒˆè¡¨ç¤ºã®é–¢æ•°
# ----------------------------------------------------------------------
def get_finding_html(finding):
    priority = finding.get('priority', 'N/A')
    p_class = {"é«˜": "high", "ä¸­": "medium", "ä½": "low"}.get(priority, "")
    html = f"<b>æŒ‡æ‘˜ç®‡æ‰€: {finding.get('location', 'N/A')}</b> <span class='priority-badge priority-{p_class}'>ç·Šæ€¥åº¦: {priority}</span><br>"
    html += f"- <b>ç¾çŠ¶:</b> {finding.get('current_state', 'N/A')}<br>"
    html += f"- <b>ææ¡ˆå·¥äº‹:</b> {finding.get('suggested_work', 'N/A')}<br>"
    if finding.get('notes'):
        html += f"- <b>å‚™è€ƒ:</b> {finding.get('notes', 'N/A')}"
    return html

def display_full_report(report_payload, files_dict):
    report_data = report_payload.get('report_data', [])
    report_title = report_payload.get('title', '')
    survey_date = report_payload.get('date', '')

    # --- ç”»é¢è¡¨ç¤ºç”¨ã®ãƒ¬ãƒãƒ¼ãƒˆ ---
    with st.container():
        st.markdown('<div class="report-container">', unsafe_allow_html=True)
        st.markdown(f"<h1>ç¾å ´åˆ†æãƒ¬ãƒãƒ¼ãƒˆ</h1>", unsafe_allow_html=True)
        c1, c2 = st.columns(2); c1.markdown(f"**ç‰©ä»¶åãƒ»æ¡ˆä»¶å:**<br>{report_title or 'ï¼ˆæœªè¨­å®šï¼‰'}", unsafe_allow_html=True); c2.markdown(f"**èª¿æŸ»æ—¥:**<br>{survey_date}", unsafe_allow_html=True)
        st.markdown("<hr>", unsafe_allow_html=True)
        st.markdown("<h2>ğŸ“Š åˆ†æçµæœã‚µãƒãƒªãƒ¼</h2>", unsafe_allow_html=True)
        total_findings = sum(len(item.get("findings", [])) for item in report_data)
        high_priority_count = sum(1 for item in report_data for f in item.get("findings", []) if f.get("priority") == "é«˜")
        m1, m2, m3 = st.columns(3); m1.metric("åˆ†æå†™çœŸæšæ•°", f"{len(report_data)} æš"); m2.metric("ç·æŒ‡æ‘˜ä»¶æ•°", f"{total_findings} ä»¶"); m3.metric("ç·Šæ€¥åº¦ã€Œé«˜ã€ã®ä»¶æ•°", f"{high_priority_count} ä»¶")
        st.markdown("<hr>", unsafe_allow_html=True)
        
        st.markdown("<h2>ğŸ“‹ è©³ç´°åˆ†æçµæœï¼ˆç”»é¢è¡¨ç¤ºç”¨ï¼‰</h2>", unsafe_allow_html=True)
        for i, item in enumerate(report_data):
            st.markdown('<div class="photo-section">', unsafe_allow_html=True)
            st.markdown(f"<h3>{i + 1}. å†™çœŸãƒ•ã‚¡ã‚¤ãƒ«: {item.get('file_name', '')}</h3>", unsafe_allow_html=True)
            col1, col2 = st.columns([2, 3])
            with col1:
                if files_dict and item.get('file_name') in files_dict:
                    st.image(files_dict[item['file_name']], use_container_width=True)
            with col2:
                findings = item.get("findings", [])
                if findings:
                    for finding in findings:
                        st.markdown(get_finding_html(finding), unsafe_allow_html=True)
                        st.markdown("---")
                elif item.get("observation"):
                    st.info(f"**ã€AIã«ã‚ˆã‚‹æ‰€è¦‹ã€‘**\n\n{item['observation']}")
                else:
                    st.success("âœ… ç‰¹ã«ä¿®ç¹•ãŒå¿…è¦ãªç®‡æ‰€ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
            st.markdown('</div>', unsafe_allow_html=True)
        st.markdown('</div>', unsafe_allow_html=True)

    # --- å°åˆ·ç”¨ã®éè¡¨ç¤ºãƒ¬ãƒãƒ¼ãƒˆ ---
    st.markdown('<div class="printable-report" style="display:none;">', unsafe_allow_html=True)
    for i in range(0, len(report_data), 3):
        st.markdown('<div class="print-grid">', unsafe_allow_html=True)
        for j in range(3):
            if i + j < len(report_data):
                item = report_data[i+j]
                file_name = item.get('file_name', '')
                image_html = ""
                if files_dict and file_name in files_dict:
                    image_bytes = files_dict[file_name].getvalue()
                    b64_img = base64.b64encode(image_bytes).decode() # â˜…ã“ã®è¡Œã§base64ãŒå¿…è¦
                    image_html = f'<div class="image-box"><img src="data:image/png;base64,{b64_img}"></div>'
                
                text_html = ""
                findings = item.get("findings", [])
                if findings:
                    for finding in findings:
                        text_html += get_finding_html(finding) + "<br>"
                elif item.get("observation"):
                    text_html = f"<b>ã€AIã«ã‚ˆã‚‹æ‰€è¦‹ã€‘</b><br>{item['observation']}"
                else:
                    text_html = "ç‰¹ã«ä¿®ç¹•ãŒå¿…è¦ãªç®‡æ‰€ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"

                st.markdown(f"""
                <div class="print-item">
                    <h3>{i+j+1}. {file_name}</h3>
                    {image_html}
                    <div class="text-box">{text_html}</div>
                </div>
                """, unsafe_allow_html=True)
        st.markdown('</div>', unsafe_allow_html=True)
    st.markdown('</div>', unsafe_allow_html=True)


# ----------------------------------------------------------------------
# 5. ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³
# ----------------------------------------------------------------------
def main():
    inject_custom_css()
    model = initialize_vertexai()

    if 'report_payload' in st.session_state:
        st.success("âœ… ãƒ¬ãƒãƒ¼ãƒˆã®ä½œæˆãŒå®Œäº†ã—ã¾ã—ãŸï¼")
        st.info("ğŸ’¡ ãƒ¬ãƒãƒ¼ãƒˆã‚’PDFã¨ã—ã¦ä¿å­˜ã™ã‚‹ã«ã¯ã€ãƒ–ãƒ©ã‚¦ã‚¶ã®å°åˆ·æ©Ÿèƒ½ï¼ˆCtrl+P ã¾ãŸã¯ Cmd+Pï¼‰ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚")
        if st.button("æ–°ã—ã„ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã™ã‚‹", key="new_from_result"):
            st.session_state.clear()
            st.rerun()
        
        display_full_report(st.session_state.report_payload, st.session_state.files_dict)
        return

    st.title("ğŸ“· AIãƒªãƒ•ã‚©ãƒ¼ãƒ ç®‡æ‰€åˆ†æï¼†å ±å‘Šæ›¸ä½œæˆ")
    st.markdown("ç¾å ´å†™çœŸã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã¨ã€AIãŒã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆå‘ã‘ã®ä¿®ç¹•ææ¡ˆãƒ¬ãƒãƒ¼ãƒˆã‚’è‡ªå‹•ä½œæˆã—ã¾ã™ã€‚")

    if not model:
        st.warning("AIãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸã€‚"); st.stop()

    report_title = st.text_input("ç‰©ä»¶åãƒ»æ¡ˆä»¶å", "ï¼ˆä¾‹ï¼‰ã€‡ã€‡ãƒ“ãƒ« 301å·å®¤ åŸçŠ¶å›å¾©å·¥äº‹")
    survey_date = st.date_input("èª¿æŸ»æ—¥", date.today())
    
    uploaded_files = st.file_uploader(
        "åˆ†æã—ãŸã„å†™çœŸã‚’é¸æŠ",
        type=["png", "jpg", "jpeg"],
        accept_multiple_files=True,
        key="file_uploader"
    )
    
    if uploaded_files:
        st.success(f"{len(uploaded_files)}ä»¶ã®å†™çœŸãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¾ã—ãŸã€‚")
    
    is_processing = st.session_state.get('processing', False)
    submitted = st.button(
        "ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã™ã‚‹",
        type="primary",
        use_container_width=True,
        disabled=not uploaded_files or is_processing
    )

    if submitted:
        st.session_state.processing = True
        st.session_state.uploaded_files = uploaded_files # åˆ†æä¸­ã«ä½¿ã†ãŸã‚ä¿å­˜
        st.session_state.report_title_val = report_title
        st.session_state.survey_date_val = survey_date
        st.rerun() # å‡¦ç†ä¸­UIã«åˆ‡ã‚Šæ›¿ãˆã‚‹

def run_analysis():
    """st.rerunã®å¾Œã«å®Ÿè¡Œã•ã‚Œã‚‹åˆ†æå‡¦ç†ã®æœ¬ä½“"""
    model = initialize_vertexai()
    uploaded_files = st.session_state.uploaded_files
    report_title = st.session_state.report_title_val
    survey_date = st.session_state.survey_date_val
    
    st.info("åˆ†æå‡¦ç†ã‚’å®Ÿè¡Œä¸­ã§ã™ã€‚ã“ã®ã¾ã¾ãŠå¾…ã¡ãã ã•ã„...")
    total_batches = math.ceil(len(uploaded_files) / BATCH_SIZE)
    progress_bar = st.progress(0, text="AIåˆ†æã®æº–å‚™ã‚’ã—ã¦ã„ã¾ã™...")
    
    final_report_data = []
    try:
        for i in range(0, len(uploaded_files), BATCH_SIZE):
            current_batch_num = (i // BATCH_SIZE) + 1
            progress_text = f"AIãŒå†™çœŸã‚’åˆ†æä¸­... (ãƒãƒƒãƒ {current_batch_num}/{total_batches})"
            progress_bar.progress(i / len(uploaded_files), text=progress_text)

            file_batch = uploaded_files[i:i + BATCH_SIZE]
            filenames = [f.name for f in file_batch]
            prompt = create_report_prompt(filenames)
            
            response_text = generate_ai_report(model, file_batch, prompt)
            batch_report_data = parse_json_response(response_text)
            
            if batch_report_data:
                final_report_data.extend(batch_report_data)
            else:
                st.error(f"ãƒãƒƒãƒ {current_batch_num} ã®åˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚")
        
        progress_bar.progress(1.0, text="åˆ†æå®Œäº†ï¼ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆä¸­ã§ã™...")
        
        st.session_state.files_dict = {f.name: f for f in uploaded_files}
        report_payload = {
            "title": report_title,
            "date": survey_date.strftime('%Yå¹´%mæœˆ%dæ—¥'),
            "report_data": final_report_data
        }
        st.session_state.report_payload = report_payload
        
    except Exception as e:
        st.error(f"åˆ†æå‡¦ç†å…¨ä½“ã§äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
    finally:
        st.session_state.processing = False
        # ä¸è¦ã«ãªã£ãŸä¸€æ™‚ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤
        for key in ['uploaded_files', 'report_title_val', 'survey_date_val']:
            if key in st.session_state:
                del st.session_state[key]
        st.rerun()

if __name__ == "__main__":
    if st.session_state.get('processing', False):
        run_analysis()
    else:
        main()
